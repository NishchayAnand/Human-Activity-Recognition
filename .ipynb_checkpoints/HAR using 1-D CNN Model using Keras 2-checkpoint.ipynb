{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 52\n",
    "# we are going to divide the data into windows of 2.5 secs\n",
    "time_steps = int(Fs*(2.5)) # 130\n",
    "overlap_size = int((Fs*(2.5))/2) # 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_windows(df, time_steps, overlap_size):\n",
    "\n",
    "    N_FEATURES = 3\n",
    "\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, overlap_size):\n",
    "        x = df['x'].values[i: i + time_steps]\n",
    "        y = df['y'].values[i: i + time_steps]\n",
    "        z = df['z'].values[i: i + time_steps]\n",
    "        \n",
    "        # Retrieve the most often used label in this segment\n",
    "        label = stats.mode(df['label'][i: i + time_steps])[0][0]\n",
    "        windows.append([x, y, z])\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    windows = np.asarray(windows).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return windows, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 16):\n",
    "    csv_location = \"Processed CSV 2/CSV\"+str(i)+\"_processed2.csv\"\n",
    "    df = pd.read_csv(csv_location, index_col=[0])\n",
    "    if(i==1):\n",
    "        X, Y = prepare_windows(df, time_steps, overlap_size)\n",
    "    else: \n",
    "        x, y = prepare_windows(df, time_steps, overlap_size)\n",
    "        X = np.concatenate((X, x), axis=0)\n",
    "        Y = np.concatenate((Y, y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3043, 130, 3), (3043,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2130, 130, 3), (913, 130, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130, 3), (130, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape, X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(2130, 130, 3, 1)\n",
    "X_test = X_test.reshape(913, 130, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2130, 130, 3, 1), (913, 130, 3, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model preparation using tensorflow keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (2, 2), activation = 'relu', input_shape = X_train[0].shape))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2130 samples, validate on 913 samples\n",
      "Epoch 1/50\n",
      "2130/2130 [==============================] - 1s 596us/sample - loss: 1.8249 - acc: 0.2099 - val_loss: 1.7289 - val_acc: 0.3198\n",
      "Epoch 2/50\n",
      "2130/2130 [==============================] - 1s 492us/sample - loss: 1.6839 - acc: 0.3141 - val_loss: 1.6143 - val_acc: 0.3943\n",
      "Epoch 3/50\n",
      "2130/2130 [==============================] - 1s 478us/sample - loss: 1.5812 - acc: 0.3620 - val_loss: 1.5521 - val_acc: 0.3724\n",
      "Epoch 4/50\n",
      "2130/2130 [==============================] - 1s 468us/sample - loss: 1.5320 - acc: 0.3808 - val_loss: 1.5010 - val_acc: 0.4042\n",
      "Epoch 5/50\n",
      "2130/2130 [==============================] - 1s 476us/sample - loss: 1.4946 - acc: 0.4019 - val_loss: 1.4624 - val_acc: 0.4513\n",
      "Epoch 6/50\n",
      "2130/2130 [==============================] - 1s 476us/sample - loss: 1.4091 - acc: 0.4300 - val_loss: 1.4499 - val_acc: 0.4765\n",
      "Epoch 7/50\n",
      "2130/2130 [==============================] - 1s 475us/sample - loss: 1.3593 - acc: 0.4746 - val_loss: 1.4083 - val_acc: 0.4973\n",
      "Epoch 8/50\n",
      "2130/2130 [==============================] - 1s 477us/sample - loss: 1.2943 - acc: 0.4939 - val_loss: 1.4075 - val_acc: 0.4874\n",
      "Epoch 9/50\n",
      "2130/2130 [==============================] - 1s 455us/sample - loss: 1.2545 - acc: 0.5286 - val_loss: 1.3860 - val_acc: 0.5060\n",
      "Epoch 10/50\n",
      "2130/2130 [==============================] - 1s 466us/sample - loss: 1.1751 - acc: 0.5258 - val_loss: 1.3921 - val_acc: 0.4984\n",
      "Epoch 11/50\n",
      "2130/2130 [==============================] - 1s 461us/sample - loss: 1.1799 - acc: 0.5413 - val_loss: 1.3884 - val_acc: 0.4863\n",
      "Epoch 12/50\n",
      "2130/2130 [==============================] - 1s 502us/sample - loss: 1.1205 - acc: 0.5685 - val_loss: 1.3745 - val_acc: 0.5093\n",
      "Epoch 13/50\n",
      "2130/2130 [==============================] - 1s 457us/sample - loss: 1.0918 - acc: 0.5887 - val_loss: 1.3929 - val_acc: 0.4984\n",
      "Epoch 14/50\n",
      "2130/2130 [==============================] - 1s 445us/sample - loss: 1.0426 - acc: 0.5939 - val_loss: 1.4074 - val_acc: 0.5060\n",
      "Epoch 15/50\n",
      "2130/2130 [==============================] - 1s 470us/sample - loss: 1.0290 - acc: 0.6070 - val_loss: 1.4541 - val_acc: 0.5027\n",
      "Epoch 16/50\n",
      "2130/2130 [==============================] - 1s 447us/sample - loss: 1.0123 - acc: 0.5977 - val_loss: 1.4378 - val_acc: 0.5093\n",
      "Epoch 17/50\n",
      "2130/2130 [==============================] - 1s 457us/sample - loss: 0.9960 - acc: 0.6160 - val_loss: 1.3972 - val_acc: 0.5356\n",
      "Epoch 18/50\n",
      "2130/2130 [==============================] - 1s 447us/sample - loss: 0.9673 - acc: 0.6258 - val_loss: 1.4486 - val_acc: 0.5279\n",
      "Epoch 19/50\n",
      "2130/2130 [==============================] - 1s 459us/sample - loss: 0.9421 - acc: 0.6347 - val_loss: 1.4004 - val_acc: 0.5345\n",
      "Epoch 20/50\n",
      "2130/2130 [==============================] - 1s 454us/sample - loss: 0.8829 - acc: 0.6545 - val_loss: 1.4507 - val_acc: 0.5225\n",
      "Epoch 21/50\n",
      "2130/2130 [==============================] - 1s 450us/sample - loss: 0.8935 - acc: 0.6545 - val_loss: 1.4516 - val_acc: 0.5246\n",
      "Epoch 22/50\n",
      "2130/2130 [==============================] - 1s 456us/sample - loss: 0.8489 - acc: 0.6582 - val_loss: 1.5163 - val_acc: 0.5400\n",
      "Epoch 23/50\n",
      "2130/2130 [==============================] - 1s 449us/sample - loss: 0.8311 - acc: 0.6883 - val_loss: 1.4527 - val_acc: 0.5575\n",
      "Epoch 24/50\n",
      "2130/2130 [==============================] - 1s 464us/sample - loss: 0.7969 - acc: 0.6765 - val_loss: 1.5032 - val_acc: 0.5345\n",
      "Epoch 25/50\n",
      "2130/2130 [==============================] - 1s 478us/sample - loss: 0.7808 - acc: 0.6934 - val_loss: 1.5079 - val_acc: 0.5444\n",
      "Epoch 26/50\n",
      "2130/2130 [==============================] - 1s 460us/sample - loss: 0.7878 - acc: 0.6798 - val_loss: 1.5716 - val_acc: 0.5630\n",
      "Epoch 27/50\n",
      "2130/2130 [==============================] - 1s 442us/sample - loss: 0.7630 - acc: 0.6869 - val_loss: 1.5779 - val_acc: 0.5553\n",
      "Epoch 28/50\n",
      "2130/2130 [==============================] - 1s 454us/sample - loss: 0.7413 - acc: 0.7113 - val_loss: 1.5193 - val_acc: 0.5444\n",
      "Epoch 29/50\n",
      "2130/2130 [==============================] - 1s 451us/sample - loss: 0.7378 - acc: 0.7117 - val_loss: 1.5712 - val_acc: 0.5487\n",
      "Epoch 30/50\n",
      "2130/2130 [==============================] - 1s 448us/sample - loss: 0.7240 - acc: 0.7117 - val_loss: 1.6385 - val_acc: 0.5619\n",
      "Epoch 31/50\n",
      "2130/2130 [==============================] - 1s 471us/sample - loss: 0.6837 - acc: 0.7291 - val_loss: 1.6449 - val_acc: 0.5378\n",
      "Epoch 32/50\n",
      "2130/2130 [==============================] - 1s 447us/sample - loss: 0.7045 - acc: 0.7249 - val_loss: 1.6308 - val_acc: 0.5542\n",
      "Epoch 33/50\n",
      "2130/2130 [==============================] - 1s 454us/sample - loss: 0.6540 - acc: 0.7413 - val_loss: 1.6422 - val_acc: 0.5531\n",
      "Epoch 34/50\n",
      "2130/2130 [==============================] - 1s 447us/sample - loss: 0.6691 - acc: 0.7380 - val_loss: 1.6993 - val_acc: 0.5542\n",
      "Epoch 35/50\n",
      "2130/2130 [==============================] - 1s 450us/sample - loss: 0.6619 - acc: 0.7362 - val_loss: 1.7713 - val_acc: 0.5553\n",
      "Epoch 36/50\n",
      "2130/2130 [==============================] - 1s 454us/sample - loss: 0.6623 - acc: 0.7380 - val_loss: 1.7334 - val_acc: 0.5520\n",
      "Epoch 37/50\n",
      "2130/2130 [==============================] - 1s 491us/sample - loss: 0.6250 - acc: 0.7451 - val_loss: 1.8507 - val_acc: 0.5455\n",
      "Epoch 38/50\n",
      "2130/2130 [==============================] - 1s 501us/sample - loss: 0.6221 - acc: 0.7484 - val_loss: 1.7404 - val_acc: 0.5586\n",
      "Epoch 39/50\n",
      "2130/2130 [==============================] - 1s 469us/sample - loss: 0.6115 - acc: 0.7559 - val_loss: 1.7601 - val_acc: 0.5619\n",
      "Epoch 40/50\n",
      "2130/2130 [==============================] - 1s 482us/sample - loss: 0.5853 - acc: 0.7601 - val_loss: 1.8592 - val_acc: 0.5706\n",
      "Epoch 41/50\n",
      "2130/2130 [==============================] - 1s 465us/sample - loss: 0.6058 - acc: 0.7685 - val_loss: 1.7964 - val_acc: 0.5553\n",
      "Epoch 42/50\n",
      "2130/2130 [==============================] - 1s 470us/sample - loss: 0.5970 - acc: 0.7502 - val_loss: 1.7592 - val_acc: 0.5641\n",
      "Epoch 43/50\n",
      "2130/2130 [==============================] - 1s 483us/sample - loss: 0.5976 - acc: 0.7662 - val_loss: 1.8530 - val_acc: 0.5641\n",
      "Epoch 44/50\n",
      "2130/2130 [==============================] - 1s 462us/sample - loss: 0.5599 - acc: 0.7737 - val_loss: 1.7439 - val_acc: 0.5739\n",
      "Epoch 45/50\n",
      "2130/2130 [==============================] - 1s 480us/sample - loss: 0.5649 - acc: 0.7803 - val_loss: 1.8966 - val_acc: 0.5586\n",
      "Epoch 46/50\n",
      "2130/2130 [==============================] - 1s 460us/sample - loss: 0.5508 - acc: 0.7765 - val_loss: 1.8393 - val_acc: 0.5641\n",
      "Epoch 47/50\n",
      "2130/2130 [==============================] - 1s 455us/sample - loss: 0.5577 - acc: 0.7742 - val_loss: 1.9093 - val_acc: 0.5586\n",
      "Epoch 48/50\n",
      "2130/2130 [==============================] - 1s 470us/sample - loss: 0.5489 - acc: 0.7826 - val_loss: 1.9336 - val_acc: 0.5663\n",
      "Epoch 49/50\n",
      "2130/2130 [==============================] - 1s 485us/sample - loss: 0.5742 - acc: 0.7728 - val_loss: 1.7969 - val_acc: 0.5630\n",
      "Epoch 50/50\n",
      "2130/2130 [==============================] - 1s 486us/sample - loss: 0.5334 - acc: 0.7883 - val_loss: 1.9976 - val_acc: 0.5531\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate = 0.001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(X_train, Y_train, epochs = 50, validation_data= (X_test, Y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
